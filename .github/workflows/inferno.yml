name: Inferno US Core Test Suite

on:
  workflow_dispatch:  # Manual trigger only for initial implementation

env:
  CARGO_TERM_COLOR: always
  RUST_MIN_STACK: 8388608
  CARGO_BUILD_JOBS: 1
  CARGO_PROFILE_DEV_DEBUG: 0
  HFS_PORT: 8088
  INFERNO_PORT: ${{ secrets.INFERNO_PORT || vars.INFERNO_PORT || '4568' }}
  # Remote Docker host (set via GitHub repository secrets or variables; leave unset for local Docker)
  DOCKER_HOST: ${{ secrets.DOCKER_HOST }}
  DOCKER_HOST_IP: ${{ secrets.DOCKER_HOST_IP }}

jobs:
  build:
    name: Build HFS
    runs-on: [self-hosted, Linux]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: stable

      - name: Configure Rust to use LLD
        run: |
          mkdir -p ~/.cargo
          rm -f ~/.cargo/config.toml
          echo '[target.x86_64-unknown-linux-gnu]' >> ~/.cargo/config.toml
          echo 'linker = "clang"' >> ~/.cargo/config.toml
          echo 'rustflags = ["-C", "link-arg=-fuse-ld=lld", "-C", "link-arg=-Wl,-zstack-size=8388608"]' >> ~/.cargo/config.toml

      - name: Build HFS
        run: cargo build -p helios-hfs --features R4,sqlite,elasticsearch,postgres

      - name: Upload HFS binary
        uses: actions/upload-artifact@v4
        with:
          name: hfs-binary
          path: target/debug/hfs
          retention-days: 1

  inferno-test:
    name: Inferno US Core ${{ matrix.version_label }} Tests (${{ matrix.backend }})
    needs: build
    runs-on: [self-hosted, Linux]
    strategy:
      fail-fast: false
      max-parallel: 3
      matrix:
        suite_id: [us_core_v311, us_core_v400, us_core_v501, us_core_v610, us_core_v700, us_core_v800]
        backend: [sqlite, sqlite-elasticsearch, postgres]
        include:
          - { suite_id: us_core_v311, version_label: "v3.1.1" }
          - { suite_id: us_core_v400, version_label: "v4.0.0" }
          - { suite_id: us_core_v501, version_label: "v5.0.1" }
          - { suite_id: us_core_v610, version_label: "v6.1.0" }
          - { suite_id: us_core_v700, version_label: "v7.0.0" }
          - { suite_id: us_core_v800, version_label: "v8.0.0" }
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download HFS binary
        uses: actions/download-artifact@v4
        with:
          name: hfs-binary
          path: target/debug

      - name: Make HFS binary executable
        run: chmod +x target/debug/hfs

      - name: Determine runner IP
        run: |
          # Get the runner's IP so the persistent Inferno container can reach HFS on this runner.
          RUNNER_IP=$(hostname -I | awk '{print $1}')
          echo "RUNNER_IP=$RUNNER_IP" >> $GITHUB_ENV
          echo "Runner IP: $RUNNER_IP"

      - name: Set version-specific variables
        run: |
          SUITE=${{ matrix.suite_id }}
          echo "TEST_GROUP_ID=${SUITE}-${SUITE}_fhir_api" >> $GITHUB_ENV

          # CapabilityStatement tests: server doesn't yet declare US Core profiles/instantiates
          OMITTED="\"${SUITE}-${SUITE}_fhir_api-${SUITE}_capability_statement-us_core_conformance_support\""
          OMITTED="${OMITTED},\"${SUITE}-${SUITE}_fhir_api-${SUITE}_capability_statement-us_core_profile_support\""
          OMITTED="${OMITTED},\"${SUITE}-${SUITE}_fhir_api-${SUITE}_capability_statement-us_core_instantiate\""
          # TLS test: HFS does not serve HTTPS
          OMITTED="${OMITTED},\"${SUITE}-${SUITE}_fhir_api-${SUITE}_capability_statement-standalone_auth_tls\""
          # DataAbsentReason: test data does not include DAR extensions/code systems
          # Note: Inferno uses "us_core_311" naming for this group across all US Core versions
          OMITTED="${OMITTED},\"${SUITE}-${SUITE}_fhir_api-us_core_311_data_absent_reason-us_core_311_data_absent_reason_extension\""
          OMITTED="${OMITTED},\"${SUITE}-${SUITE}_fhir_api-us_core_311_data_absent_reason-us_core_311_data_absent_reason_code_system\""

          case "$SUITE" in
            us_core_v501|us_core_v610|us_core_v700|us_core_v800)
              # ServiceRequest uses US-edition SNOMED code (467771000124109) not in International Edition; Inferno validator can't resolve it
              OMITTED="${OMITTED},\"${SUITE}-${SUITE}_fhir_api-${SUITE}_service_request-${SUITE}_service_request_validation_test\""
              ;;
          esac

          case "$SUITE" in
            us_core_v610|us_core_v700)
              # No Practitioner references found in test data for these versions
              OMITTED="${OMITTED},\"${SUITE}-${SUITE}_fhir_api-${SUITE}_practitioner-${SUITE}_practitioner_address_test\""
              ;;
          esac

          case "$SUITE" in
            us_core_v700|us_core_v800)
              # Inferno fhir_client gem bug with UUID-based Location references
              OMITTED="${OMITTED},\"${SUITE}-${SUITE}_fhir_api-${SUITE}_location-${SUITE}_location_address_search_test\""
              ;;
          esac

          case "$SUITE" in
            us_core_v800)
              # v8.0.0 changed us-core-sex extension type from code to Coding; shared test data uses valueCode (correct for v6.1.0/v7.0.0)
              OMITTED="${OMITTED},\"${SUITE}-${SUITE}_fhir_api-${SUITE}_patient-${SUITE}_patient_validation_test\""
              # QuestionnaireResponse linkId text must match referenced Questionnaire definition
              OMITTED="${OMITTED},\"${SUITE}-${SUITE}_fhir_api-${SUITE}_questionnaire_response-${SUITE}_questionnaire_response_validation_test\""
              ;;
          esac

          echo "OMITTED_TESTS=[${OMITTED}]" >> $GITHUB_ENV

      - name: Start Elasticsearch
        if: matrix.backend == 'sqlite-elasticsearch'
        run: |
          ES_CONTAINER="es-${{ matrix.suite_id }}-${{ matrix.backend }}"
          docker rm -f $ES_CONTAINER 2>/dev/null || true
          docker run -d --name $ES_CONTAINER -p 0:9200 \
            -e "discovery.type=single-node" \
            -e "xpack.security.enabled=false" \
            -e "ES_JAVA_OPTS=-Xms512m -Xmx512m" \
            elasticsearch:8.15.0

          echo "ES_CONTAINER=$ES_CONTAINER" >> $GITHUB_ENV

          echo "Waiting for Elasticsearch to be ready..."
          for i in {1..30}; do
            ES_PORT=$(docker port $ES_CONTAINER 9200 2>/dev/null | head -1 | sed 's/.*://')
            if [ -n "$ES_PORT" ]; then
              if curl -sf http://$DOCKER_HOST_IP:$ES_PORT/_cluster/health > /dev/null 2>&1; then
                echo "Elasticsearch is ready on port $ES_PORT"
                echo "ES_PORT=$ES_PORT" >> $GITHUB_ENV
                exit 0
              fi
            fi
            echo "Attempt $i/30: Elasticsearch not ready yet..."
            sleep 2
          done
          echo "Elasticsearch failed to start"
          docker logs $ES_CONTAINER
          exit 1

      - name: Start PostgreSQL
        if: matrix.backend == 'postgres'
        run: |
          PG_CONTAINER="pg-${{ matrix.suite_id }}"
          docker rm -f $PG_CONTAINER 2>/dev/null || true
          docker run -d --name $PG_CONTAINER -p 0:5432 \
            -e POSTGRES_USER=helios \
            -e POSTGRES_PASSWORD=helios \
            -e POSTGRES_DB=helios \
            postgres:16

          echo "PG_CONTAINER=$PG_CONTAINER" >> $GITHUB_ENV

          echo "Waiting for PostgreSQL to be ready..."
          for i in {1..30}; do
            if docker exec $PG_CONTAINER pg_isready -U helios > /dev/null 2>&1; then
              PG_PORT=$(docker port $PG_CONTAINER 5432 | head -1 | sed 's/.*://')
              echo "PostgreSQL is ready on port $PG_PORT"
              echo "PG_PORT=$PG_PORT" >> $GITHUB_ENV
              exit 0
            fi
            echo "Attempt $i/30: PostgreSQL not ready yet..."
            sleep 2
          done
          echo "PostgreSQL failed to start"
          docker logs $PG_CONTAINER
          exit 1

      - name: Start HFS server
        run: |
          if [ "${{ matrix.backend }}" = "sqlite-elasticsearch" ]; then
            HFS_STORAGE_BACKEND=sqlite-elasticsearch \
            HFS_ELASTICSEARCH_NODES=http://$DOCKER_HOST_IP:$ES_PORT \
            ./target/debug/hfs --database-url :memory: --log-level info --port $HFS_PORT --host 0.0.0.0 &
          elif [ "${{ matrix.backend }}" = "postgres" ]; then
            HFS_STORAGE_BACKEND=postgres \
            HFS_PG_HOST=$DOCKER_HOST_IP \
            HFS_PG_PORT=$PG_PORT \
            HFS_PG_DBNAME=helios \
            HFS_PG_USER=helios \
            HFS_PG_PASSWORD=helios \
            ./target/debug/hfs --log-level info --port $HFS_PORT --host 0.0.0.0 &
          else
            ./target/debug/hfs --database-url :memory: --log-level info --port $HFS_PORT --host 0.0.0.0 &
          fi
          echo $! > /tmp/hfs.pid
          echo "HFS_PID=$(cat /tmp/hfs.pid)" >> $GITHUB_ENV

      - name: Wait for HFS to be ready
        run: |
          echo "Waiting for HFS to start..."
          for i in {1..30}; do
            if curl -sf http://localhost:$HFS_PORT/health > /dev/null 2>&1; then
              echo "HFS is ready"
              exit 0
            fi
            echo "Attempt $i/30: HFS not ready yet..."
            sleep 2
          done
          echo "HFS failed to start"
          exit 1

      - name: Load Inferno test data into HFS
        run: |
          ./crates/hfs/tests/inferno/install.sh

      - name: Wait for Inferno to be ready
        run: |
          echo "Waiting for persistent Inferno container to respond..."
          for i in {1..30}; do
            if curl -sf "http://$DOCKER_HOST_IP:$INFERNO_PORT/api/test_suites" > /dev/null 2>&1; then
              echo "Inferno is ready on $DOCKER_HOST_IP:$INFERNO_PORT"
              exit 0
            fi
            echo "Attempt $i/30: Inferno not ready yet..."
            sleep 2
          done
          echo "Inferno is not reachable at http://$DOCKER_HOST_IP:$INFERNO_PORT"
          exit 1

      - name: Create results directory
        run: mkdir -p inferno-results

      - name: Run Inferno tests
        run: |
          # Create a test session for US Core ${{ matrix.version_label }}
          echo "Creating test session for ${{ matrix.suite_id }}..."
          SESSION_RESPONSE=$(curl -s -X POST "http://$DOCKER_HOST_IP:$INFERNO_PORT/api/test_sessions?test_suite_id=${{ matrix.suite_id }}")
          SESSION_ID=$(echo "$SESSION_RESPONSE" | jq -r '.id')

          if [ -z "$SESSION_ID" ] || [ "$SESSION_ID" = "null" ]; then
            echo "Failed to create test session"
            echo "$SESSION_RESPONSE"
            exit 1
          fi

          echo "Test session created: $SESSION_ID"
          echo "$SESSION_RESPONSE" > inferno-results/session.json

          # Start the test run
          # Note: RUNNER_IP is used so the Inferno container can reach HFS on the runner
          # Note: smart_auth_info with auth_type=public allows testing without SMART OAuth
          echo "Starting test run..."
          RUN_RESPONSE=$(curl -s -X POST "http://$DOCKER_HOST_IP:$INFERNO_PORT/api/test_runs" \
            -H "Content-Type: application/json" \
            -d "{
              \"test_session_id\": \"$SESSION_ID\",
              \"test_group_id\": \"$TEST_GROUP_ID\",
              \"inputs\": [
                {\"name\": \"url\", \"value\": \"http://$RUNNER_IP:$HFS_PORT\"},
                {\"name\": \"patient_ids\", \"value\": \"85,355,907,908,us-core-client-tests-patient\"},
                {\"name\": \"smart_auth_info\", \"value\": \"{\\\"auth_type\\\":\\\"public\\\"}\"}
              ]
            }")

          RUN_ID=$(echo "$RUN_RESPONSE" | jq -r '.id')

          if [ -z "$RUN_ID" ] || [ "$RUN_ID" = "null" ]; then
            echo "Failed to start test run"
            echo "$RUN_RESPONSE"
            exit 1
          fi

          echo "Test run started: $RUN_ID"
          echo "$RUN_RESPONSE" > inferno-results/run.json

          # Poll for test run completion
          echo "Polling for results..."
          MAX_POLLS=120
          POLL_INTERVAL=10

          for i in $(seq 1 $MAX_POLLS); do
            # Check test run status directly (more reliable than counting results)
            RUN_STATUS=$(curl -s "http://$DOCKER_HOST_IP:$INFERNO_PORT/api/test_runs/$RUN_ID" | jq -r '.status')

            # Get results for progress display (filter to individual tests only, not group aggregations)
            RESULTS=$(curl -s "http://$DOCKER_HOST_IP:$INFERNO_PORT/api/test_runs/$RUN_ID/results")
            TOTAL=$(echo "$RESULTS" | jq '[.[] | select(.test_id)] | length')
            PASS=$(echo "$RESULTS" | jq '[.[] | select(.test_id and .result == "pass")] | length')
            FAIL=$(echo "$RESULTS" | jq '[.[] | select(.test_id and .result == "fail")] | length')
            SKIP=$(echo "$RESULTS" | jq '[.[] | select(.test_id and .result == "skip")] | length')
            ERROR=$(echo "$RESULTS" | jq '[.[] | select(.test_id and .result == "error")] | length')
            OMIT=$(echo "$RESULTS" | jq '[.[] | select(.test_id and .result == "omit")] | length')

            echo "Poll $i/$MAX_POLLS: Status=$RUN_STATUS Total=$TOTAL Pass=$PASS Fail=$FAIL Skip=$SKIP Error=$ERROR Omit=$OMIT"

            # Check if test run is complete
            if [ "$RUN_STATUS" = "done" ]; then
              echo "Test run complete!"
              echo "$RESULTS" > inferno-results/results.json
              break
            fi

            if [ $i -eq $MAX_POLLS ]; then
              echo "Test run timed out"
              echo "$RESULTS" > inferno-results/results.json
            fi

            sleep $POLL_INTERVAL
          done

      - name: Check test results
        run: |
          if [ ! -f inferno-results/results.json ]; then
            echo "No results file found"
            exit 1
          fi

          RESULTS=$(cat inferno-results/results.json)

          # Count failures excluding omitted tests
          FAIL=$(echo "$RESULTS" | jq --argjson omit "$OMITTED_TESTS" \
            '[.[] | select(.test_id and (.result == "fail" or .result == "error") and (.test_id | IN($omit[]) | not))] | length')
          OMITTED_COUNT=$(echo "$RESULTS" | jq --argjson omit "$OMITTED_TESTS" \
            '[.[] | select(.test_id and (.test_id | IN($omit[])))] | length')

          echo "Failures (excluding $OMITTED_COUNT omitted tests): $FAIL"

          if [ "$FAIL" -gt 0 ]; then
            echo "::error::$FAIL test(s) failed (excluding omitted)"
            echo "$RESULTS" | jq -r --argjson omit "$OMITTED_TESTS" \
              '.[] | select(.test_id and (.result == "fail" or .result == "error") and (.test_id | IN($omit[]) | not)) | "  \(.test_id): \(.result) - \(.result_message // "No message" | .[0:200])"'
            exit 1
          fi

          echo "All tests passed (with $OMITTED_COUNT omitted)"

      - name: Generate test summary
        if: always()
        run: |
          if [ -f inferno-results/results.json ]; then
            echo "## Inferno US Core ${{ matrix.version_label }} Test Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            RESULTS=$(cat inferno-results/results.json)

            # Count only individual tests (exclude group aggregations which have test_group_id instead of test_id)
            TOTAL=$(echo "$RESULTS" | jq '[.[] | select(.test_id)] | length')
            PASS=$(echo "$RESULTS" | jq '[.[] | select(.test_id and .result == "pass")] | length')
            FAIL=$(echo "$RESULTS" | jq --argjson omit "$OMITTED_TESTS" \
              '[.[] | select(.test_id and .result == "fail" and (.test_id | IN($omit[]) | not))] | length')
            SKIP=$(echo "$RESULTS" | jq '[.[] | select(.test_id and .result == "skip")] | length')
            ERROR=$(echo "$RESULTS" | jq --argjson omit "$OMITTED_TESTS" \
              '[.[] | select(.test_id and .result == "error" and (.test_id | IN($omit[]) | not))] | length')
            OMIT=$(echo "$RESULTS" | jq '[.[] | select(.test_id and .result == "omit")] | length')
            OMITTED_COUNT=$(echo "$RESULTS" | jq --argjson omit "$OMITTED_TESTS" \
              '[.[] | select(.test_id and (.test_id | IN($omit[])))] | length')

            echo "| Status | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| :white_check_mark: Pass | $PASS |" >> $GITHUB_STEP_SUMMARY
            echo "| :x: Fail | $FAIL |" >> $GITHUB_STEP_SUMMARY
            echo "| :warning: Error | $ERROR |" >> $GITHUB_STEP_SUMMARY
            echo "| :fast_forward: Skip | $SKIP |" >> $GITHUB_STEP_SUMMARY
            echo "| :arrow_right: Omit | $OMIT |" >> $GITHUB_STEP_SUMMARY
            echo "| :heavy_minus_sign: Omitted (known) | $OMITTED_COUNT |" >> $GITHUB_STEP_SUMMARY
            echo "| **Total** | **$TOTAL** |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # List omitted tests
            if [ "$OMITTED_COUNT" -gt 0 ]; then
              echo "### Omitted Tests (known expected failures)" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "$RESULTS" | jq -r --argjson omit "$OMITTED_TESTS" \
                '.[] | select(.test_id and (.test_id | IN($omit[]))) | "- **\(.test_id)**: \(.result) - \(.result_message // "No message" | .[0:200])"' >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi

            # List failed tests (excluding omitted)
            if [ "$FAIL" -gt 0 ] || [ "$ERROR" -gt 0 ]; then
              echo "### Failed/Error Tests" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "$RESULTS" | jq -r --argjson omit "$OMITTED_TESTS" \
                '.[] | select((.result == "fail" or .result == "error") and .test_id and (.test_id | IN($omit[]) | not)) | "- **\(.test_id)**: \(.result) - \(.result_message // "No message" | .[0:200])"' >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "## Inferno US Core ${{ matrix.version_label }} Test Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo ":warning: No results file found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: inferno-test-results-${{ matrix.suite_id }}-${{ matrix.backend }}
          path: inferno-results/
          retention-days: 30

      - name: Cleanup
        if: always()
        run: |
          echo "Stopping HFS..."
          if [ -f /tmp/hfs.pid ]; then
            kill $(cat /tmp/hfs.pid) 2>/dev/null || true
            rm -f /tmp/hfs.pid
          fi

          echo "Stopping Elasticsearch..."
          docker rm -f "${ES_CONTAINER:-none}" 2>/dev/null || true

          echo "Stopping PostgreSQL..."
          docker rm -f "${PG_CONTAINER:-none}" 2>/dev/null || true

          echo "Cleanup complete"
